{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0c6b1b",
   "metadata": {},
   "source": [
    "## PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b0359d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a session:\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Permission').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "18a2ad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-BFEIRED:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Permission</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2516e9430a0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cba47222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries:\n",
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "08a88e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 193 entries, 0 to 192\n",
      "Data columns (total 6 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   country                       193 non-null    object \n",
      " 1   beer_servings                 193 non-null    int64  \n",
      " 2   spirit_servings               193 non-null    int64  \n",
      " 3   wine_servings                 193 non-null    int64  \n",
      " 4   total_litres_of_pure_alcohol  193 non-null    float64\n",
      " 5   continent                     170 non-null    object \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 9.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Read dataframe in pandas:\n",
    "df = pd.read_csv(\"Alcohol.csv\")\n",
    "\n",
    "\n",
    "#To check the datatypes and non null count:\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eb2e1758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0='country', _c1='beer_servings', _c2='spirit_servings', _c3='wine_servings', _c4='total_litres_of_pure_alcohol', _c5='continent')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To read the csv file using spark:\n",
    "dfspark =spark.read.csv(\"Alcohol.csv\")\n",
    "dfspark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "732e5f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To read the csv using spark and assigning header names also:\n",
    "dfspark = spark.read.option('header','true').csv(\"Alcohol.csv\", inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e998afe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(country='Afghanistan', beer_servings=0, spirit_servings=0, wine_servings=0, total_litres_of_pure_alcohol=0.0, continent='AS'),\n",
       " Row(country='Albania', beer_servings=89, spirit_servings=132, wine_servings=54, total_litres_of_pure_alcohol=4.9, continent='EU'),\n",
       " Row(country='Algeria', beer_servings=25, spirit_servings=0, wine_servings=14, total_litres_of_pure_alcohol=0.7, continent='AF'),\n",
       " Row(country='Andorra', beer_servings=245, spirit_servings=138, wine_servings=312, total_litres_of_pure_alcohol=12.4, continent='EU'),\n",
       " Row(country='Angola', beer_servings=217, spirit_servings=57, wine_servings=45, total_litres_of_pure_alcohol=5.9, continent='AF')]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To read the csv\n",
    "dfspark =spark.read.csv(\"Alcohol.csv\", header=True, inferSchema=True)\n",
    "dfspark.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2cc20f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the datatype of dataframe\n",
    "type(dfspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "db50af04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- beer_servings: integer (nullable = true)\n",
      " |-- spirit_servings: integer (nullable = true)\n",
      " |-- wine_servings: integer (nullable = true)\n",
      " |-- total_litres_of_pure_alcohol: double (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the schema\n",
    "dfspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc7bb5",
   "metadata": {},
   "source": [
    "# PySpark basic operations:\n",
    "    1. To select all the columns \n",
    "    2. To select multiple columns\n",
    "    3. To check the data types of columns\n",
    "    4. To add the column and drop the column\n",
    "    5. Describe functionality\n",
    "    6. Column rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "78c303cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'beer_servings',\n",
       " 'spirit_servings',\n",
       " 'wine_servings',\n",
       " 'total_litres_of_pure_alcohol',\n",
       " 'continent']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4bc6036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|          country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To check the dataframe\n",
    "dfspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ce66aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|          country|\n",
      "+-----------------+\n",
      "|      Afghanistan|\n",
      "|          Albania|\n",
      "|          Algeria|\n",
      "|          Andorra|\n",
      "|           Angola|\n",
      "|Antigua & Barbuda|\n",
      "|        Argentina|\n",
      "|          Armenia|\n",
      "|        Australia|\n",
      "|          Austria|\n",
      "|       Azerbaijan|\n",
      "|          Bahamas|\n",
      "|          Bahrain|\n",
      "|       Bangladesh|\n",
      "|         Barbados|\n",
      "|          Belarus|\n",
      "|          Belgium|\n",
      "|           Belize|\n",
      "|            Benin|\n",
      "|           Bhutan|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To select the particular column \n",
    "dfspark.select('country').show() #By default it shows first 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5726e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+\n",
      "|          country|beer_servings|\n",
      "+-----------------+-------------+\n",
      "|      Afghanistan|            0|\n",
      "|          Albania|           89|\n",
      "|          Algeria|           25|\n",
      "|          Andorra|          245|\n",
      "|           Angola|          217|\n",
      "|Antigua & Barbuda|          102|\n",
      "|        Argentina|          193|\n",
      "|          Armenia|           21|\n",
      "|        Australia|          261|\n",
      "|          Austria|          279|\n",
      "+-----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To select the multiple columns with first 10 rows\n",
    "dfspark.select(['country','beer_servings']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "801645c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+\n",
      "|          country|beer_servings|spirit_servings|\n",
      "+-----------------+-------------+---------------+\n",
      "|      Afghanistan|            0|              0|\n",
      "|          Albania|           89|            132|\n",
      "|          Algeria|           25|              0|\n",
      "|          Andorra|          245|            138|\n",
      "|           Angola|          217|             57|\n",
      "|Antigua & Barbuda|          102|            128|\n",
      "|        Argentina|          193|             25|\n",
      "|          Armenia|           21|            179|\n",
      "|        Australia|          261|             72|\n",
      "|          Austria|          279|             75|\n",
      "+-----------------+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To select the multiple columns with first 10 rows\n",
    "dfspark.select(['country','beer_servings','spirit_servings']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c792be0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('country', 'string'),\n",
       " ('beer_servings', 'int'),\n",
       " ('spirit_servings', 'int'),\n",
       " ('wine_servings', 'int'),\n",
       " ('total_litres_of_pure_alcohol', 'double'),\n",
       " ('continent', 'string')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check dtypes of all the columns:\n",
    "dfspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "85b45f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------------+-----------------+-----------------+----------------------------+---------+\n",
      "|summary|    country|     beer_servings|  spirit_servings|    wine_servings|total_litres_of_pure_alcohol|continent|\n",
      "+-------+-----------+------------------+-----------------+-----------------+----------------------------+---------+\n",
      "|  count|        193|               193|              193|              193|                         193|      193|\n",
      "|   mean|       null|106.16062176165804|80.99481865284974|49.45077720207254|           4.717098445595855|     null|\n",
      "| stddev|       null| 101.1431025393134|88.28431210968618|79.69759845763012|           3.773298164356082|     null|\n",
      "|    min|Afghanistan|                 0|                0|                0|                         0.0|       AF|\n",
      "|    max|   Zimbabwe|               376|              438|              370|                        14.4|       SA|\n",
      "+-------+-----------+------------------+-----------------+-----------------+----------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Describe function\n",
    "dfspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "08017089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|          country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2556312f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+-------------------+\n",
      "|          country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|wine_servings_after|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+-------------------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|                 10|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|                 64|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|                 24|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|                322|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|                 55|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|                 55|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|                231|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|                 21|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|                222|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|                201|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|                 15|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|                 61|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|                 17|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|                 10|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|                 46|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|                 52|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|                222|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|                 18|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|                 23|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|                 10|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding column in dataframe:\n",
    "dfspark.withColumn('wine_servings_after',dfspark['wine_servings']+10).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bc4297f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|          country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark.show()\n",
    "#As we can see that new column is not added to the original dataframe \n",
    "#Becuase there is no inplace function in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0ca9690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+-------------------+\n",
      "|          country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|wine_servings_after|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+-------------------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|                 10|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|                 64|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|                 24|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|                322|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|                 55|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|                 55|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|                231|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|                 21|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|                222|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|                201|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|                 15|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|                 61|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|                 17|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|                 10|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|                 46|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|                 52|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|                222|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|                 18|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|                 23|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|                 10|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#There is no inplace function in Pyspark. \n",
    "#In order to reflect the output in original dataframe we have to assign it to a new variable.\n",
    "dfspark = dfspark.withColumn('wine_servings_after',dfspark['wine_servings']+10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b2778281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the column\n",
    "dfspark = dfspark.drop(\"wine_servings_after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6bd7e7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|          country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "50b13a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|          Country|beer_servings|spirit_servings|wine_servings|total_litres_of_pure_alcohol|continent|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "|      Afghanistan|            0|              0|            0|                         0.0|       AS|\n",
      "|          Albania|           89|            132|           54|                         4.9|       EU|\n",
      "|          Algeria|           25|              0|           14|                         0.7|       AF|\n",
      "|          Andorra|          245|            138|          312|                        12.4|       EU|\n",
      "|           Angola|          217|             57|           45|                         5.9|       AF|\n",
      "|Antigua & Barbuda|          102|            128|           45|                         4.9|       NA|\n",
      "|        Argentina|          193|             25|          221|                         8.3|       SA|\n",
      "|          Armenia|           21|            179|           11|                         3.8|       EU|\n",
      "|        Australia|          261|             72|          212|                        10.4|       OC|\n",
      "|          Austria|          279|             75|          191|                         9.7|       EU|\n",
      "|       Azerbaijan|           21|             46|            5|                         1.3|       EU|\n",
      "|          Bahamas|          122|            176|           51|                         6.3|       NA|\n",
      "|          Bahrain|           42|             63|            7|                         2.0|       AS|\n",
      "|       Bangladesh|            0|              0|            0|                         0.0|       AS|\n",
      "|         Barbados|          143|            173|           36|                         6.3|       NA|\n",
      "|          Belarus|          142|            373|           42|                        14.4|       EU|\n",
      "|          Belgium|          295|             84|          212|                        10.5|       EU|\n",
      "|           Belize|          263|            114|            8|                         6.8|       NA|\n",
      "|            Benin|           34|              4|           13|                         1.1|       AF|\n",
      "|           Bhutan|           23|              0|            0|                         0.4|       AS|\n",
      "+-----------------+-------------+---------------+-------------+----------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Rename the column\n",
    "dfspark = dfspark.withColumnRenamed('country','Country')\n",
    "dfspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b762672",
   "metadata": {},
   "source": [
    "# PySpark handling missing values:\n",
    "1. Dropping columns\n",
    "2. Dropping rows\n",
    "3. Various parameters involved in dropping\n",
    "4. Missing values imputations with Mean, Median and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "f8800518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-BFEIRED:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Permission</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2516e9430a0>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark  = SparkSession.builder.appName('New').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "03e54587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+---------+\n",
      "|   Name| Age|Salary|     City|\n",
      "+-------+----+------+---------+\n",
      "|  Rahul|  26| 30000|Bangalore|\n",
      "|Abhinav|  26| 34000|     Pune|\n",
      "|   Sonu|  23| 34000|   Mumbai|\n",
      "|  Akash|  24| 45000|     null|\n",
      "|  Rohit|null| 35000|   Shimla|\n",
      "|   null|  23|  null|   Manali|\n",
      "| Sanjay|  30| 56000|   Mysore|\n",
      "|   null|  21| 53000|    Hubli|\n",
      "|  Suman|  28| 45000|   Mumbai|\n",
      "|  Akash|null| 23000|Hyderabad|\n",
      "|   null|null|  null|     null|\n",
      "| Aayush|  30| 38000|    Solan|\n",
      "+-------+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv(\"Book1.csv\",header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0840a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+\n",
      "|   Name| Age|Salary|\n",
      "+-------+----+------+\n",
      "|  Rahul|  26| 30000|\n",
      "|Abhinav|  26| 34000|\n",
      "|   Sonu|  23| 34000|\n",
      "|  Akash|  24| 45000|\n",
      "|  Rohit|null| 35000|\n",
      "|   null|  23|  null|\n",
      "| Sanjay|  30| 56000|\n",
      "|   null|  21| 53000|\n",
      "|  Suman|  28| 45000|\n",
      "|  Akash|null| 23000|\n",
      "|   null|null|  null|\n",
      "| Aayush|  30| 38000|\n",
      "+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To drop a column on temporary basis:\n",
    "df_pyspark.drop('City').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "29c4307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+---------+\n",
      "|   Name|Age|Salary|     City|\n",
      "+-------+---+------+---------+\n",
      "|  Rahul| 26| 30000|Bangalore|\n",
      "|Abhinav| 26| 34000|     Pune|\n",
      "|   Sonu| 23| 34000|   Mumbai|\n",
      "| Sanjay| 30| 56000|   Mysore|\n",
      "|  Suman| 28| 45000|   Mumbai|\n",
      "| Aayush| 30| 38000|    Solan|\n",
      "+-------+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To drop null values\n",
    "df_pyspark.na.drop().show()\n",
    "\n",
    "#If we will not assign anything in drop() then \n",
    "#It will drop all the null values whereever it is (null) present at any row or index position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6e29bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+---------+\n",
      "|   Name|Age|Salary|     City|\n",
      "+-------+---+------+---------+\n",
      "|  Rahul| 26| 30000|Bangalore|\n",
      "|Abhinav| 26| 34000|     Pune|\n",
      "|   Sonu| 23| 34000|   Mumbai|\n",
      "| Sanjay| 30| 56000|   Mysore|\n",
      "|  Suman| 28| 45000|   Mumbai|\n",
      "| Aayush| 30| 38000|    Solan|\n",
      "+-------+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop the null values using how='any' inside drop function\n",
    "df_pyspark.na.drop(how='any').show() \n",
    "\n",
    "#It will drop all the rows wherever there is a null value in a row.\n",
    "#And by default how='any' in drop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "15c8c17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+---------+\n",
      "|   Name| Age|Salary|     City|\n",
      "+-------+----+------+---------+\n",
      "|  Rahul|  26| 30000|Bangalore|\n",
      "|Abhinav|  26| 34000|     Pune|\n",
      "|   Sonu|  23| 34000|   Mumbai|\n",
      "|  Akash|  24| 45000|     null|\n",
      "|  Rohit|null| 35000|   Shimla|\n",
      "|   null|  23|  null|   Manali|\n",
      "| Sanjay|  30| 56000|   Mysore|\n",
      "|   null|  21| 53000|    Hubli|\n",
      "|  Suman|  28| 45000|   Mumbai|\n",
      "|  Akash|null| 23000|Hyderabad|\n",
      "| Aayush|  30| 38000|    Solan|\n",
      "+-------+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Drop the null values using how='all' inside drop function\n",
    "df_pyspark.na.drop(how='all').show() \n",
    "\n",
    "#It will delete the rows whenever all the values under the columns in a row are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0ea18bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+---------+\n",
      "|   Name| Age|Salary|     City|\n",
      "+-------+----+------+---------+\n",
      "|  Rahul|  26| 30000|Bangalore|\n",
      "|Abhinav|  26| 34000|     Pune|\n",
      "|   Sonu|  23| 34000|   Mumbai|\n",
      "|  Akash|  24| 45000|     null|\n",
      "|  Rohit|null| 35000|   Shimla|\n",
      "| Sanjay|  30| 56000|   Mysore|\n",
      "|   null|  21| 53000|    Hubli|\n",
      "|  Suman|  28| 45000|   Mumbai|\n",
      "|  Akash|null| 23000|Hyderabad|\n",
      "| Aayush|  30| 38000|    Solan|\n",
      "+-------+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop(Thresh=3)\n",
    "df_pyspark.na.drop(how='all', thresh=3).show()\n",
    "\n",
    "#Thresh=3 means atleast 3 non null values will be there. \n",
    "#If condition not satisfies then drop() will drop that particular row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "05cdd8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+---------+\n",
      "|   Name|Age|Salary|     City|\n",
      "+-------+---+------+---------+\n",
      "|  Rahul| 26| 30000|Bangalore|\n",
      "|Abhinav| 26| 34000|     Pune|\n",
      "|   Sonu| 23| 34000|   Mumbai|\n",
      "|  Akash| 24| 45000|     null|\n",
      "|   null| 23|  null|   Manali|\n",
      "| Sanjay| 30| 56000|   Mysore|\n",
      "|   null| 21| 53000|    Hubli|\n",
      "|  Suman| 28| 45000|   Mumbai|\n",
      "| Aayush| 30| 38000|    Solan|\n",
      "+-------+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop(subset='Age')\n",
    "df_pyspark.na.drop(subset='Age').show()\n",
    "\n",
    "#It will drop all the rows wherever the age values are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8cc5cc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+---------+\n",
      "|   Name|Age|Salary|     City|\n",
      "+-------+---+------+---------+\n",
      "|  Rahul| 26| 30000|Bangalore|\n",
      "|Abhinav| 26| 34000|     Pune|\n",
      "|   Sonu| 23| 34000|   Mumbai|\n",
      "|  Akash| 24| 45000|     null|\n",
      "|  Rohit|  0| 35000|   Shimla|\n",
      "|   null| 23|     0|   Manali|\n",
      "| Sanjay| 30| 56000|   Mysore|\n",
      "|   null| 21| 53000|    Hubli|\n",
      "|  Suman| 28| 45000|   Mumbai|\n",
      "|  Akash|  0| 23000|Hyderabad|\n",
      "|   null|  0|     0|     null|\n",
      "| Aayush| 30| 38000|    Solan|\n",
      "+-------+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the missing values with 0 in Age and Salary column:\n",
    "df_pyspark.na.fill(0,['Salary','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "89a49f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+---------+\n",
      "|   Name| Age|Salary|     City|\n",
      "+-------+----+------+---------+\n",
      "|  Rahul|  26| 30000|Bangalore|\n",
      "|Abhinav|  26| 34000|     Pune|\n",
      "|   Sonu|  23| 34000|   Mumbai|\n",
      "|  Akash|  24| 45000|  Missing|\n",
      "|  Rohit|null| 35000|   Shimla|\n",
      "|Missing|  23|  null|   Manali|\n",
      "| Sanjay|  30| 56000|   Mysore|\n",
      "|Missing|  21| 53000|    Hubli|\n",
      "|  Suman|  28| 45000|   Mumbai|\n",
      "|  Akash|null| 23000|Hyderabad|\n",
      "|Missing|null|  null|  Missing|\n",
      "| Aayush|  30| 38000|    Solan|\n",
      "+-------+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the missing values with 'Missing' in Name column:\n",
    "df_pyspark.na.fill('Missing',['Name','City']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "fc07a04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+---------+\n",
      "|   Name|Age|Salary|     City|\n",
      "+-------+---+------+---------+\n",
      "|  Rahul| 26| 30000|Bangalore|\n",
      "|Abhinav| 26| 34000|     Pune|\n",
      "|   Sonu| 23| 34000|   Mumbai|\n",
      "|  Akash| 24| 45000|     null|\n",
      "|  Rohit| 25| 35000|   Shimla|\n",
      "|   null| 23| 39300|   Manali|\n",
      "| Sanjay| 30| 56000|   Mysore|\n",
      "|   null| 21| 53000|    Hubli|\n",
      "|  Suman| 28| 45000|   Mumbai|\n",
      "|  Akash| 25| 23000|Hyderabad|\n",
      "|   null| 25| 39300|     null|\n",
      "| Aayush| 30| 38000|    Solan|\n",
      "+-------+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the missing values with mean using imputer:\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['Age','Salary'],\n",
    "                 outputCols=['Age','Salary']).setStrategy(\"mean\")\n",
    "\n",
    "\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e4ee3473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+---------+\n",
      "|   Name|Age|Salary|     City|\n",
      "+-------+---+------+---------+\n",
      "|  Rahul| 26| 30000|Bangalore|\n",
      "|Abhinav| 26| 34000|     Pune|\n",
      "|   Sonu| 23| 34000|   Mumbai|\n",
      "|  Akash| 24| 45000|     null|\n",
      "|  Rohit| 26| 35000|   Shimla|\n",
      "|   null| 23| 35000|   Manali|\n",
      "| Sanjay| 30| 56000|   Mysore|\n",
      "|   null| 21| 53000|    Hubli|\n",
      "|  Suman| 28| 45000|   Mumbai|\n",
      "|  Akash| 26| 23000|Hyderabad|\n",
      "|   null| 26| 35000|     null|\n",
      "| Aayush| 30| 38000|    Solan|\n",
      "+-------+---+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the missing values with median using imputer:\n",
    "\n",
    "\n",
    "imputer = Imputer(inputCols=['Age','Salary'],\n",
    "                 outputCols=['Age','Salary']).setStrategy(\"median\")\n",
    "\n",
    "\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7f25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a55965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad0659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b549b7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8fd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2c54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
